{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2734496,"sourceType":"datasetVersion","datasetId":1654566,"isSourceIdPinned":false}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Setup and Dataset Download\n\n\n","metadata":{}},{"cell_type":"code","source":"!pip install rouge_score\n!pip install evaluate\nimport numpy as np \nimport pandas as pd\nimport kagglehub\nimport os\nimport kagglehub\nimport re\nfrom datasets import Dataset\nimport transformers\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\nimport evaluate\n\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n\n\npath = kagglehub.dataset_download(\"gowrishankarp/newspaper-text-summarization-cnn-dailymail\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:51:18.244876Z","iopub.execute_input":"2025-11-02T15:51:18.245088Z","iopub.status.idle":"2025-11-02T15:51:56.157489Z","shell.execute_reply.started":"2025-11-02T15:51:18.245069Z","shell.execute_reply":"2025-11-02T15:51:56.156858Z"}},"outputs":[{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.1)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge_score) (2024.2.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=ec6a79ac94fe714ba455b8b109e0d96bc1115157023ef2d7cc4cc21fc7ae17e4\n  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\nCollecting evaluate\n  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.6.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.4)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.5.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.33.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nCollecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.13)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.6.15)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec, evaluate\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.5.1\n    Uninstalling fsspec-2025.5.1:\n      Successfully uninstalled fsspec-2025.5.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed evaluate-0.4.6 fsspec-2025.3.0\n","output_type":"stream"},{"name":"stderr","text":"2025-11-02 15:51:38.261744: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1762098698.464437      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1762098698.530029      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/validation.csv\n/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv\n/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv\nPath to dataset files: /kaggle/input/newspaper-text-summarization-cnn-dailymail\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Reading the data","metadata":{}},{"cell_type":"markdown","source":"## Load Dataset\n\n###  Load the training, validation, and test splits into pandas DataFrames","metadata":{}},{"cell_type":"code","source":"training_set = pd.read_csv('/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/train.csv')\ntest_set = pd.read_csv('/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/test.csv')\nvalidation_set = pd.read_csv('/kaggle/input/newspaper-text-summarization-cnn-dailymail/cnn_dailymail/validation.csv')\ntraining_set.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:51:56.158222Z","iopub.execute_input":"2025-11-02T15:51:56.158753Z","iopub.status.idle":"2025-11-02T15:52:23.282300Z","shell.execute_reply.started":"2025-11-02T15:51:56.158725Z","shell.execute_reply":"2025-11-02T15:52:23.281511Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"                                         id  \\\n0  0001d1afc246a7964130f43ae940af6bc6c57f01   \n1  0002095e55fcbd3a2f366d9bf92a95433dc305ef   \n2  00027e965c8264c35cc1bc55556db388da82b07f   \n3  0002c17436637c4fe1837c935c04de47adb18e9a   \n4  0003ad6ef0c37534f80b55b4235108024b407f0b   \n\n                                             article  \\\n0  By . Associated Press . PUBLISHED: . 14:11 EST...   \n1  (CNN) -- Ralph Mata was an internal affairs li...   \n2  A drunk driver who killed a young woman in a h...   \n3  (CNN) -- With a breezy sweep of his pen Presid...   \n4  Fleetwood are the only team still to have a 10...   \n\n                                          highlights  \n0  Bishop John Folda, of North Dakota, is taking ...  \n1  Criminal complaint: Cop used his role to help ...  \n2  Craig Eccleston-Todd, 27, had drunk at least t...  \n3  Nina dos Santos says Europe must be ready to a...  \n4  Fleetwood top of League One after 2-0 win at S...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>article</th>\n      <th>highlights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>\n      <td>By . Associated Press . PUBLISHED: . 14:11 EST...</td>\n      <td>Bishop John Folda, of North Dakota, is taking ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>\n      <td>(CNN) -- Ralph Mata was an internal affairs li...</td>\n      <td>Criminal complaint: Cop used his role to help ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00027e965c8264c35cc1bc55556db388da82b07f</td>\n      <td>A drunk driver who killed a young woman in a h...</td>\n      <td>Craig Eccleston-Todd, 27, had drunk at least t...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0002c17436637c4fe1837c935c04de47adb18e9a</td>\n      <td>(CNN) -- With a breezy sweep of his pen Presid...</td>\n      <td>Nina dos Santos says Europe must be ready to a...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0003ad6ef0c37534f80b55b4235108024b407f0b</td>\n      <td>Fleetwood are the only team still to have a 10...</td>\n      <td>Fleetwood top of League One after 2-0 win at S...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"###  Droped Unused Column","metadata":{}},{"cell_type":"code","source":"training_set.drop(columns = ['id'],inplace = True)\ntest_set.drop(columns = ['id'],inplace = True)\nvalidation_set.drop(columns = ['id'],inplace = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:52:23.284231Z","iopub.execute_input":"2025-11-02T15:52:23.284527Z","iopub.status.idle":"2025-11-02T15:52:23.318308Z","shell.execute_reply.started":"2025-11-02T15:52:23.284500Z","shell.execute_reply":"2025-11-02T15:52:23.317570Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## checking for nulls","metadata":{}},{"cell_type":"code","source":"print(training_set.isnull().sum())\nprint(training_set.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:52:23.320277Z","iopub.execute_input":"2025-11-02T15:52:23.320586Z","iopub.status.idle":"2025-11-02T15:52:23.417404Z","shell.execute_reply.started":"2025-11-02T15:52:23.320560Z","shell.execute_reply":"2025-11-02T15:52:23.416630Z"}},"outputs":[{"name":"stdout","text":"article       0\nhighlights    0\ndtype: int64\n(287113, 2)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"###  droped the duplicates","metadata":{}},{"cell_type":"code","source":"training_set.drop_duplicates(inplace = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:52:23.418245Z","iopub.execute_input":"2025-11-02T15:52:23.418991Z","iopub.status.idle":"2025-11-02T15:52:27.331390Z","shell.execute_reply.started":"2025-11-02T15:52:23.418966Z","shell.execute_reply":"2025-11-02T15:52:27.330644Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## checking the data size","metadata":{}},{"cell_type":"code","source":"print(training_set.shape)\nprint(validation_set.shape)\nprint(test_set.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:52:27.332140Z","iopub.execute_input":"2025-11-02T15:52:27.332377Z","iopub.status.idle":"2025-11-02T15:52:27.337043Z","shell.execute_reply.started":"2025-11-02T15:52:27.332360Z","shell.execute_reply":"2025-11-02T15:52:27.336301Z"}},"outputs":[{"name":"stdout","text":"(284015, 2)\n(13368, 2)\n(11490, 2)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Sampling the Dataset\n\n###  Since the CNN/DailyMail dataset is large,  \n###  we take smaller random samples for training","metadata":{}},{"cell_type":"code","source":"training_set = training_set.sample(n=40_000, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:52:27.337948Z","iopub.execute_input":"2025-11-02T15:52:27.338191Z","iopub.status.idle":"2025-11-02T15:52:27.384659Z","shell.execute_reply.started":"2025-11-02T15:52:27.338168Z","shell.execute_reply":"2025-11-02T15:52:27.383856Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"training_set.shape\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:52:27.385362Z","iopub.execute_input":"2025-11-02T15:52:27.385572Z","iopub.status.idle":"2025-11-02T15:52:27.391092Z","shell.execute_reply.started":"2025-11-02T15:52:27.385556Z","shell.execute_reply":"2025-11-02T15:52:27.390374Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(40000, 2)"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"## Text Cleaning\n\n###  For summarization, we apply minimal cleaning:  \n###  - Remove extra spaces and line breaks.  \n###  - Keep punctuation, casing, and sentence structure intact (important for meaning).  \n\n###  This ensures the text remains close to the original while removing noise.\n","metadata":{}},{"cell_type":"code","source":"def clean_text(text):\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:52:27.393495Z","iopub.execute_input":"2025-11-02T15:52:27.393690Z","iopub.status.idle":"2025-11-02T15:52:27.402909Z","shell.execute_reply.started":"2025-11-02T15:52:27.393675Z","shell.execute_reply":"2025-11-02T15:52:27.402252Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"training_set['article'] = training_set['article'].apply(clean_text)\ntraining_set['highlights'] = training_set['highlights'].apply(clean_text)\n\nvalidation_set['article'] = validation_set['article'].apply(clean_text)\nvalidation_set['highlights'] = validation_set['highlights'].apply(clean_text)\n\ntest_set['article'] = test_set['article'].apply(clean_text)\ntest_set['highlights'] = test_set['highlights'].apply(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:52:27.403538Z","iopub.execute_input":"2025-11-02T15:52:27.403728Z","iopub.status.idle":"2025-11-02T15:52:42.484953Z","shell.execute_reply.started":"2025-11-02T15:52:27.403715Z","shell.execute_reply":"2025-11-02T15:52:42.484259Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Convert DataFrames to Hugging Face Datasets\n\n###   Convert the pandas DataFrames for training, validation, and testing  \n###   into the `datasets.Dataset` format, which is required for use with the Hugging Face Trainer API.\n","metadata":{}},{"cell_type":"code","source":"train_dataset = Dataset.from_pandas(training_set)\ntest_dataset = Dataset.from_pandas(test_set)\nvalidation_dataset = Dataset.from_pandas(validation_set)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:52:42.485865Z","iopub.execute_input":"2025-11-02T15:52:42.486143Z","iopub.status.idle":"2025-11-02T15:52:44.944165Z","shell.execute_reply.started":"2025-11-02T15:52:42.486117Z","shell.execute_reply":"2025-11-02T15:52:44.943519Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"###   Load the pretrained **T5-base tokenizer** from Hugging Face.  \n###   The tokenizer converts raw text into token IDs that the model can understand,  \n###   and will also handle decoding model outputs back into text.","metadata":{}},{"cell_type":"code","source":"model_name = 't5-base'\ntokenizer = AutoTokenizer.from_pretrained(model_name,use_fast = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:52:44.945052Z","iopub.execute_input":"2025-11-02T15:52:44.945322Z","iopub.status.idle":"2025-11-02T15:52:48.959624Z","shell.execute_reply.started":"2025-11-02T15:52:44.945301Z","shell.execute_reply":"2025-11-02T15:52:48.958871Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1eb61788d044497dbdb5aff4e1d4304b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0713e81dd9854f519c8107f4dd1d909a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b25925d8a3e4275a9ac783e16f2b0a0"}},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"## Preprocessing Function\n\n###   Define a preprocessing function to tokenize the dataset:  \n###   - **Articles** are truncated/padded to a maximum length of 512 tokens.  \n###   - **Summaries (highlights)** are truncated/padded to a maximum length of 128 tokens.  \n###   - The tokenized summaries are stored as labels for training.","metadata":{}},{"cell_type":"code","source":"max_input_length = 512\nmax_target_length = 128\n\ndef preprocess_data(data):\n    model_inputs = tokenizer(\n        data[\"article\"],\n        max_length=max_input_length,\n        truncation=True,\n        padding=\"max_length\"  \n    )\n\n    labels = tokenizer(\n        data[\"highlights\"],\n        max_length=max_target_length,\n        truncation=True,\n        padding=\"max_length\" \n    )\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:52:48.960446Z","iopub.execute_input":"2025-11-02T15:52:48.960730Z","iopub.status.idle":"2025-11-02T15:52:48.965218Z","shell.execute_reply.started":"2025-11-02T15:52:48.960706Z","shell.execute_reply":"2025-11-02T15:52:48.964500Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"train_dataset = train_dataset.map(preprocess_data, batched=True)\nvalidation_dataset   = validation_dataset.map(preprocess_data, batched=True)\ntest_dataset  = test_dataset.map(preprocess_data, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-02T15:52:48.966591Z","iopub.execute_input":"2025-11-02T15:52:48.966884Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/40000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c0c1be96d414c2687f032c9fb0dda7a"}},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"## Load Pretrained Model and Data Collator\n\n### - Load the pretrained **T5-base** model for sequence-to-sequence learning.  \n###   - Use a `DataCollatorForSeq2Seq` to handle dynamic padding and batching during training.  \n###   - Suppress unnecessary log messages for cleaner output.\n","metadata":{}},{"cell_type":"code","source":"transformers.logging.set_verbosity_error()\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name)\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluation Metric (ROUGE)\n\n###  Define the evaluation function using **ROUGE scores**, which are standard for text summarization:  \n###  - Decode model predictions and labels back into text.  \n###  - Replace `-100` values in labels (ignored tokens) with the padding token ID.  \n###  - Compute ROUGE metrics (ROUGE-1, ROUGE-2, ROUGE-L) with stemming enabled.  \n###  - Return the F-measure for each metric.\n","metadata":{}},{"cell_type":"code","source":"rouge = evaluate.load(\"rouge\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    \n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    \n    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n    \n    result = {k: v.mid.fmeasure if hasattr(v, \"mid\") else v for k, v in result.items()}\n    return result\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training the Model\n\n###  Set up the `Seq2SeqTrainer` with the model, datasets, tokenizer, and data collator.  \n###  - Evaluate and save checkpoints every 500 steps.  \n###  - Use gradient accumulation, mixed precision (FP16), and gradient checkpointing for efficiency.  \n###  - Track ROUGE scores and load the best model at the end.  \n###  - Save the trained model and tokenizer for later use.\n","metadata":{}},{"cell_type":"code","source":"model.gradient_checkpointing_enable()\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./results\",\n    eval_strategy=\"steps\",\n    eval_steps=500,     \n    save_strategy=\"steps\",\n    save_steps=500,            \n    learning_rate=2e-5,               \n    per_device_train_batch_size=8,    \n    per_device_eval_batch_size=8,     \n    gradient_accumulation_steps=4,    \n    num_train_epochs=3,              \n    weight_decay=0.01,                \n    save_total_limit=3,               \n    predict_with_generate=True,       \n    fp16=True,                        \n    logging_dir=\"./logs\",\n    logging_steps=50,                \n    warmup_ratio=0.1,                 \n    report_to=\"none\",\n    load_best_model_at_end=True,\n    metric_for_best_model=\"rougeL\",\n    greater_is_better=True,\n    disable_tqdm=False\n)\n\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=validation_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics\n)\n\ntrainer.train()\n\nmodel.save_pretrained(\"/kaggle/working/model\")\ntokenizer.save_pretrained(\"/kaggle/working/model\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Continue Training for Metric Improvement\n\nContinuing training for 1 additional epoch to boost ROUGE metrics, using:\n- Lower learning rate (1e-5) for stable updates\n- Larger effective batch size (gradient accumulation = 8)\n- Resume from last checkpoint\n\nThis enhances performance without restarting from scratch.\n","metadata":{}},{"cell_type":"code","source":"training_args.num_train_epochs += 1             \ntraining_args.learning_rate = 1e-5            \ntraining_args.gradient_accumulation_steps = 8\ntraining_args.eval_steps = 625\ntraining_args.save_steps = 625\n\n\ntrainer.train(resume_from_checkpoint=True)\n\nmodel.save_pretrained(\"/kaggle/working/model_epoch4\")\ntokenizer.save_pretrained(\"/kaggle/working/model_epoch4\")\n","metadata":{"trusted":true,"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluating the model","metadata":{}},{"cell_type":"markdown","source":"#### epoch 3","metadata":{}},{"cell_type":"code","source":"print(\"Evaluation started...\")\nmetrics = trainer.evaluate(eval_dataset=test_dataset)\nprint(\"Evaluation finished.\")\nprint(f\"Test Metrics = {metrics}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### epoch 4   ","metadata":{}},{"cell_type":"code","source":"from transformers import T5ForConditionalGeneration, T5Tokenizer\nimport torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ntokenizer = T5Tokenizer.from_pretrained(\"/kaggle/working/model_epoch4\")\nmodel = T5ForConditionalGeneration.from_pretrained(\"/kaggle/working/model_epoch4\")\n\nmodel.to(device)\n\ntrainer.model = model\n\nprint(\"Evaluation started...\")\nmetrics = trainer.evaluate(eval_dataset=test_dataset)\nprint(\"Evaluation finished.\")\nprint(f\"Test Metrics = {metrics}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}